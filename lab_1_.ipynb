{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFRljRKYwznNybybu+fySR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nann72/L-m-Lab1-main/blob/main/lab_1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лабораторна робота №1 – Product Reviews"
      ],
      "metadata": {
        "id": "4cDHv_KxPFRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import twitter_samples, stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n"
      ],
      "metadata": {
        "id": "lvMvBvcjPKCl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ЗАВДАННЯ 2: Попередня обробка тексту"
      ],
      "metadata": {
        "id": "ObvjTrPOPPP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tweet(tweet):\n",
        "    \"\"\"\n",
        "    Токенізація, видалення стоп-слів, стемінг\n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "\n",
        "    tokenizer = TweetTokenizer(\n",
        "        preserve_case=False,\n",
        "        strip_handles=True,\n",
        "        reduce_len=True\n",
        "    )\n",
        "\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if word not in stopwords_english and word not in string.punctuation:\n",
        "            tweets_clean.append(stemmer.stem(word))\n",
        "\n",
        "    return tweets_clean\n"
      ],
      "metadata": {
        "id": "MSp5BQZOPSZJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ЗАВДАННЯ 3: Побудова словника частотності\n"
      ],
      "metadata": {
        "id": "HiclCvOFPS4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_freqs(tweets, ys):\n",
        "    \"\"\"\n",
        "    freqs[(word, label)] = count\n",
        "    \"\"\"\n",
        "    ys = np.squeeze(ys).tolist()\n",
        "    freqs = {}\n",
        "\n",
        "    for y, tweet in zip(ys, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            freqs[(word, y)] = freqs.get((word, y), 0) + 1\n",
        "\n",
        "    return freqs"
      ],
      "metadata": {
        "id": "u2QshmNIPUm2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ЗАВДАННЯ 4: Логістична регресія\n"
      ],
      "metadata": {
        "id": "js2-2RR_PWqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    m = x.shape[0]\n",
        "    y = y.reshape(-1, 1)\n",
        "\n",
        "    for i in range(num_iters):\n",
        "        z = np.dot(x, theta)\n",
        "        h = sigmoid(z)\n",
        "\n",
        "        epsilon = 1e-15\n",
        "        h = np.clip(h, epsilon, 1 - epsilon)\n",
        "\n",
        "        J = (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
        "        grad = (1 / m) * np.dot(x.T, (h - y))\n",
        "\n",
        "        theta = theta - alpha * grad\n",
        "\n",
        "        if i % 200 == 0:\n",
        "            print(f\"Ітерація {i}, J = {J:.6f}\")\n",
        "\n",
        "    return J, theta\n"
      ],
      "metadata": {
        "id": "eNALeFVEPZOF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ЗАВДАННЯ 5: Ознаки та передбачення\n"
      ],
      "metadata": {
        "id": "IXyAPzsyPbvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(tweet, freqs):\n",
        "    \"\"\"\n",
        "    [bias, positive_freq, negative_freq]\n",
        "    \"\"\"\n",
        "    words = process_tweet(tweet)\n",
        "    x = np.zeros((1, 3))\n",
        "    x[0, 0] = 1\n",
        "\n",
        "    for word in words:\n",
        "        x[0, 1] += freqs.get((word, 1.0), 0)\n",
        "        x[0, 2] += freqs.get((word, 0.0), 0)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def predict_tweet(tweet, freqs, theta):\n",
        "    x = extract_features(tweet, freqs)\n",
        "    return sigmoid(np.dot(x, theta))\n",
        "\n",
        "\n",
        "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
        "    y_hat = []\n",
        "\n",
        "    for tweet in test_x:\n",
        "        y_pred = predict_tweet(tweet, freqs, theta)\n",
        "        y_hat.append(1.0 if y_pred > 0.5 else 0.0)\n",
        "\n",
        "    return np.mean(np.array(y_hat) == np.squeeze(test_y))\n"
      ],
      "metadata": {
        "id": "hcK2i_xJPcAE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ГОЛОВНИЙ БЛОК\n"
      ],
      "metadata": {
        "id": "gujGeKF1SMgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    nltk.download('twitter_samples')\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "    print(\"Завантаження корпусу...\")\n",
        "\n",
        "    pos = twitter_samples.strings('positive_tweets.json')\n",
        "    neg = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "    train_pos = pos[:4000]\n",
        "    test_pos = pos[4000:]\n",
        "    train_neg = neg[:4000]\n",
        "    test_neg = neg[4000:]\n",
        "\n",
        "    train_x = train_pos + train_neg\n",
        "    test_x = test_pos + test_neg\n",
        "\n",
        "    train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
        "    test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))\n",
        "\n",
        "    print(\"Побудова словника...\")\n",
        "    freqs = build_freqs(train_x, train_y)\n",
        "\n",
        "    print(\"Навчання моделі...\")\n",
        "\n",
        "    X = np.zeros((len(train_x), 3))\n",
        "    for i in range(len(train_x)):\n",
        "        X[i, :] = extract_features(train_x[i], freqs)\n",
        "\n",
        "    alpha = 1e-9\n",
        "    num_iters = 1500\n",
        "\n",
        "    J, theta = gradientDescent(X, train_y, np.zeros((3, 1)), alpha, num_iters)\n",
        "\n",
        "    print(\"\\nНавчання завершено\")\n",
        "    print(\"Втрати:\", J)\n",
        "    print(\"Theta:\", np.squeeze(theta))\n",
        "\n",
        "    accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
        "    print(f\"\\nТочність: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    print(\"\\nТестування власного твіту:\")\n",
        "    tweet = \"I am very happy and excited about this project\"\n",
        "    pred = predict_tweet(tweet, freqs, theta)\n",
        "    print(tweet)\n",
        "    print(\"Позитивний\" if pred > 0.5 else \"Негативний\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsKINOe_SL1c",
        "outputId": "81f4e102-74b9-4122-b6c1-5a859a8558a3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Завантаження корпусу...\n",
            "Побудова словника...\n",
            "Навчання моделі...\n",
            "Ітерація 0, J = 0.693147\n",
            "Ітерація 200, J = 0.522064\n",
            "Ітерація 400, J = 0.421057\n",
            "Ітерація 600, J = 0.355746\n",
            "Ітерація 800, J = 0.310570\n",
            "Ітерація 1000, J = 0.277694\n",
            "Ітерація 1200, J = 0.252807\n",
            "Ітерація 1400, J = 0.233366\n",
            "\n",
            "Навчання завершено\n",
            "Втрати: 0.22524410259587288\n",
            "Theta: [ 5.97380718e-08  5.37857205e-04 -5.58847110e-04]\n",
            "\n",
            "Точність: 99.65%\n",
            "\n",
            "Тестування власного твіту:\n",
            "I am very happy and excited about this project\n",
            "Позитивний\n"
          ]
        }
      ]
    }
  ]
}